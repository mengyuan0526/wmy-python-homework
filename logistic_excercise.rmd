---
title: "Logistic回归"
author: "王梦圆"
date: "2020-02"
output:
  bookdown::html_document2:
    fig_caption: true
    highlight: haddock
    keep_md: true
    md_extensions: +east_asian_line_breaks
    number_sections: true
    pandoc_args:
    - --filter
    - pandoc-crossref
    - -M
    - eqnPrefix=
    seq_numbering: false
    toc: true
  bookdown::pdf_document2:
    keep_tex: true
    latex_engine: xelatex
    md_extensions: +east_asian_line_breaks
    pandoc_args:
    - --listing
    - --filter
    - pandoc-crossref
    toc: false
  slidy_presentation:
    highlight: haddock
  bookdown::word_document2:
    fig_caption: true
    md_extensions: +east_asian_line_breaks
    pandoc_args:
    - --filter
    - pandoc-crossref
    reference_docx: ./style/word-styles-02.docx
  ioslides_presentation:
    highlight: haddock
    slide_level: 3
  beamer_presentation:
    keep_tex: true
    latex_engine: xelatex
    toc: true
    pandoc_args:
    - --listing
    - --filter
    - pandoc-crossref
    slide_level: 3
    template: ./style/beamer-template.tex
csl: ./style/chinese-gb7714-2005-numeric.csl
css: ./style/markdown.css
bibliography: Bibfile.bib
eqnPrefixTemplate: ($$i$$)
institute: 中南财经政法大学统计与数学学院
link-citations: true
linkReferences: true
chapters: true
tableEqns: false
autoEqnLabels: false
---


```{r setup, echo=F, purl=F}
knitr::opts_knit$set(root.dir = getwd())
knitr::opts_chunk$set(echo = TRUE, results = 'hide')
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
knitr::opts_chunk$set(out.height="0.5\\textwidth", fig.width=5, fig.height=3, fig.align="center")
```

```{r prepare, echo=F, purl=F}
rm(list=ls())
options(digits=4)
options(scipen=100)
graphics.off()
Sys.setlocale("LC_ALL", "Chinese")
```
#### 选择Zelig包里面的turnout数据集，这个数据集是为了确定投票率与被选举人的种族(race)、年龄(age)、受教育程度(educate)和收入(income)是否有关。因变量vote是0-1型变量，赞成为1，反对为0。种族（race）变量是一个分类型自变量，在进行回归分析时，可以将“white”记为0，“others”记为1.下面对该数据集进行二分类Logistc回归分析。
```{python}
import numpy as np
import pandas as pd
import statsmodels.api as sm 
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
df = sm.datasets.get_rdataset("turnout",package="Zelig",site="D:/github_repo/Rdatasets").data
df

#对数据进行处理：去空值，处理分类变量race
df.isnull().sum()#没有空值
df['race']=df['race'].replace("white",0)
df['race']=df['race'].replace("others",1)
df['race'].unique()
df.index=np.arange(df.shape[0])
X=df.iloc[:,:4]
X
Y=df['vote']
p=Y.sum()/len(Y)#投票比率为0.746

#将数据集随机划分为训练子集和测试子集，并返回划分好的样本和标签
X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)

#拟合logistic回归方程

results=sm.Logit(y_train,X_train).fit()
print(results.summary())

```
Logistic回归方程：
$$\log \frac{p}{1-p}=-0.5874 * \text { race }+0.0063 * \text { age }+0.0367 * \text { educate }+0.1559 * \text { income }
$$
根据输出的结果显示，在显著性水平为0.05下，四个变量的P值均小于0.05，即四个自变量种族、年龄、受教育程度和收入都对是否决定投票都有显著影响。




#### 利用KMsurv包里面的aids数据集，利用Logistic回归分析法调查二分类变量adult与infect、induct的关系。infect和induct变量都为连续型变量。

```{python}
import numpy as np
import pandas as pd
import statsmodels.api as sm 
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
dat = sm.datasets.get_rdataset("aids",package="KMsurv",site="D:/github_repo/Rdatasets").data
dat

#对数据进行处理：去空值，处理分类变量race
dat.isnull().sum()#没有空值
dat.index=np.arange(dat.shape[0])
X=dat.iloc[:,:2]
Y=dat['adult']
p=Y.sum()/len(Y)

#将数据集随机划分为训练子集和测试子集，并返回划分好的样本和标签
X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)

#拟合logistic回归方程
results=sm.Logit(y_train,X_train).fit()
print(results.summary())

```
回归方程：
$$\log \frac{p}{1-p}=0.1037 * \text { infect }+0.7287 * \text { induct }$$
又因为infect变量的P值为0.103，在显著性水平0.05下，infect变量对因变量adult率影响不显著，因此，除去infect变量后再次进行Logistic回归分析.

```{python}
X_new=dat['induct']
X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.2,random_state=0)
results=sm.Logit(y_train,X_train).fit()
print(results.summary())
predictions = 
results.predict(X_test)  
```
回归方程：
$$\log \frac{p}{1-p}=0.9269 * \text { induct }$$
变量induct的P值为0，说明变量induct的影响是显著的。

